"""
éŸ³å£°å…¥åŠ›ãƒ„ãƒ¼ãƒ« Phase S-1 - éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å®Ÿè£…ç‰ˆ
Escã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ã„ã‚‹é–“éŒ²éŸ³ã—ã€é›¢ã™ã¨éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¦ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«æŒ¿å…¥
"""

import sounddevice as sd
import numpy as np
import pyautogui
from faster_whisper import WhisperModel
from pynput import keyboard
import scipy.io.wavfile as wav
import os
import time
import threading
import subprocess

class VoiceInputTool:
    def __init__(self):
        print("ğŸ¤ éŸ³å£°å…¥åŠ›ãƒ„ãƒ¼ãƒ« Phase S-1 åˆæœŸåŒ–ä¸­...")
        
        # åŸºæœ¬è¨­å®š
        self.sample_rate = 16000
        self.is_recording = False
        self.audio_data = []
        self.stream = None
        self.temp_dir = "temp"
        self.temp_file = os.path.join(self.temp_dir, "current_recording.wav")
        
        # tempãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(self.temp_dir, exist_ok=True)
        
        # Whisperãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        print("ğŸ§  Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        self.model = WhisperModel("small", device="cpu", compute_type="int8")
        print("âœ… åˆæœŸåŒ–å®Œäº†ï¼")
        print("\n" + "="*50)
        print("ğŸ¯ ä½¿ç”¨æ–¹æ³•:")
        print("  ğŸ“Œ Escã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ã„ã‚‹é–“éŒ²éŸ³")
        print("  ğŸ“Œ ã‚­ãƒ¼ã‚’é›¢ã™ã¨éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›")
        print("  ğŸ“Œ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ğŸµãƒ”ãƒƒ(é–‹å§‹) â†’ ğŸµãƒ”ãƒ”ãƒƒ(å®Œäº†)")
        print("  ğŸ“Œ Ctrl+C ã§çµ‚äº†")
        print("="*50 + "\n")

        # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–
        print("ğŸ”§ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–ä¸­...")
        subprocess.run(['pbcopy'], input="", text=True)
        print("âœ… ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†")

    def play_sound_async(self, sound_type):
        """ğŸµ éåŒæœŸéŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å†ç”Ÿï¼ˆæœ€çµ‚ç‰ˆï¼‰"""
        def play():
            sounds = {
                'start': 'Glass',      # éŒ²éŸ³é–‹å§‹: ã‚¯ãƒªã‚¹ã‚¿ãƒ«éŸ³
                'complete': 'Submarine', # éŒ²éŸ³å®Œäº†: æ·±ã‚ã®å®Œäº†éŸ³
                'error': 'Funk'        # ã‚¨ãƒ©ãƒ¼: ç›®ç«‹ã¤ãŒä¸å¿«ã§ãªã„
            }
            try:
                subprocess.run(['afplay', f'/System/Library/Sounds/{sounds[sound_type]}.aiff'], 
                            check=False)
            except:
                pass
        
        threading.Thread(target=play, daemon=True).start()

    def audio_callback(self, indata, frames, time, status):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            print(f"âš ï¸ éŸ³å£°å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {status}")
        if self.is_recording:
            self.audio_data.extend(indata.copy().flatten())

    def start_recording(self):
        """éŒ²éŸ³é–‹å§‹"""
        if self.is_recording:
            return
            
        print("ğŸ¤ éŒ²éŸ³é–‹å§‹...")
        self.is_recording = True
        self.audio_data = []
        self.recording_start_time = time.time()
        
        # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: éŒ²éŸ³é–‹å§‹ï¼ˆéåŒæœŸï¼‰
        self.play_sound_async('start')
        
        # éŒ²éŸ³é–‹å§‹å‡¦ç†ï¼ˆæœ€å„ªå…ˆï¼‰
        try:
            self.stream = sd.InputStream(
                samplerate=self.sample_rate,
                channels=1,
                callback=self.audio_callback,
                dtype=np.float32
            )
            self.stream.start()
        except Exception as e:
            print(f"âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            self.play_sound_async('error')
            self.is_recording = False

    def stop_recording(self):
        """éŒ²éŸ³åœæ­¢ã¨éŸ³å£°å‡¦ç†"""
        if not self.is_recording:
            return
            
        print("â¹ï¸ éŒ²éŸ³åœæ­¢")
        # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: éŒ²éŸ³åœæ­¢
        self.play_sound_async('complete')
        
        self.is_recording = False
        
        try:
            if self.stream:
                self.stream.stop()
                self.stream.close()
                self.stream = None
        except Exception as e:
            print(f"âš ï¸ éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            self.play_sound_async('error')
        
        # éŸ³å£°å‡¦ç†ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
        threading.Thread(target=self.process_audio, daemon=True).start()

    def insert_text_via_clipboard(self, text):
        """AppleScript + ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰çµŒç”±ã§ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥ï¼ˆãƒ•ã‚©ãƒ¼ã‚«ã‚¹ä¿®æ­£ç‰ˆï¼‰"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼
            subprocess.run(['pbcopy'], input=text, text=True)
            
            # ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’å‰ã®ã‚¢ãƒ—ãƒªã«æˆ»ã—ã¦ã‹ã‚‰è²¼ã‚Šä»˜ã‘
            script = '''
            tell application "System Events"
                set frontApp to name of first application process whose frontmost is true
                if frontApp contains "Python" or frontApp contains "voice_input" then
                    key code 48 using command down
                    delay 0.2
                end if
            end tell
            tell application "System Events" to keystroke "v" using command down
            '''
            
            # AppleScriptå®Ÿè¡Œç›´å‰ã«ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰å†è¨­å®š
            subprocess.run(['pbcopy'], input=text, text=True)
            
            result = subprocess.run(['osascript', '-e', script], capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥å®Œäº†")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _fallback_clipboard_insert(self, text):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®pyautoguiæ–¹å¼"""
        print("ğŸ” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼å®Ÿè¡Œä¸­...")
        try:
            # æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼
            process = subprocess.Popen(
                'pbcopy', 
                stdin=subprocess.PIPE, 
                text=True
            )
            process.communicate(text)
            
            # å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒšãƒ¼ã‚¹ãƒˆ
            time.sleep(0.1)
            
            # Cmd+V ã§ãƒšãƒ¼ã‚¹ãƒˆ
            pyautogui.hotkey('cmd', 'v')
            
            print("âœ… ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥å®Œäº†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ï¼‰")
            return True
            
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æŒ¿å…¥ã‚‚å¤±æ•—: {e}")
            return False

    def process_audio(self):
        """éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¦ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«æŒ¿å…¥"""
        try:
            # Phase 7-C: è©³ç´°æ™‚é–“æ¸¬å®šé–‹å§‹
            process_start = time.time()
            
            if len(self.audio_data) == 0:
                print("âŒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¨ãƒ©ãƒ¼
                self.play_sound_async('error')
                return
            
            # æ¸¬å®šãƒã‚¤ãƒ³ãƒˆ1: éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–‹å§‹
            audio_prep_start = time.time()
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’numpyé…åˆ—ã«å¤‰æ›
            audio_array = np.array(self.audio_data, dtype=np.float32)
            duration = len(audio_array) / self.sample_rate
            
            print(f"ğŸ“Š éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿: {len(audio_array)}ã‚µãƒ³ãƒ—ãƒ«, {duration:.1f}ç§’")
            
            # æœ€ä½éŒ²éŸ³æ™‚é–“ãƒã‚§ãƒƒã‚¯
            if duration < 0.5:
                print("âš ï¸ éŒ²éŸ³æ™‚é–“ãŒçŸ­ã™ãã¾ã™ï¼ˆæœ€ä½0.5ç§’å¿…è¦ï¼‰")
                # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¨ãƒ©ãƒ¼
                self.play_sound_async('error')
                return
            
            # éŸ³å£°ãƒ¬ãƒ™ãƒ«ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            max_level = np.max(np.abs(audio_array))
            rms_level = np.sqrt(np.mean(audio_array**2))
            print(f"ğŸ”Š éŸ³å£°ãƒ¬ãƒ™ãƒ« - Max: {max_level:.4f}, RMS: {rms_level:.4f}")
            
            if max_level < 0.01:
                print("âš ï¸ éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒä½ã™ãã¾ã™")
                # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¨ãƒ©ãƒ¼
                self.play_sound_async('error')
                return
            
            # æ¸¬å®šãƒã‚¤ãƒ³ãƒˆ2: WAVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜é–‹å§‹
            wav_save_start = time.time()
            
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            wav_data = (audio_array * 32767).astype(np.int16)
            wav.write(self.temp_file, self.sample_rate, wav_data)
            print(f"ğŸ’¾ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {self.temp_file}")
            
            # æ¸¬å®šãƒã‚¤ãƒ³ãƒˆ3: WAVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†
            wav_save_end = time.time()
            
            # Whisperå‡¦ç†æ™‚é–“æ¸¬å®šé–‹å§‹
            whisper_start = time.time()
            
            # Whisperã§éŸ³å£°èªè­˜
            print("ğŸ§  éŸ³å£°èªè­˜å‡¦ç†ä¸­...")
            segments, info = self.model.transcribe(
                self.temp_file,
                language="ja",
                beam_size=1,
                best_of=1,
                temperature=0.0,
                no_speech_threshold=0.6,
                log_prob_threshold=-1.0,
                compression_ratio_threshold=2.4
            )
            
            whisper_end = time.time()
            
            print(f"ğŸ“‹ èªè­˜è¨€èª: {info.language} (ç¢ºç‡: {info.language_probability:.2f})")
            
            # æ¸¬å®šãƒã‚¤ãƒ³ãƒˆ4: ãƒ†ã‚­ã‚¹ãƒˆçµåˆé–‹å§‹
            text_combine_start = time.time()
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†
            print("ğŸ§  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ä¸­...")
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå–å¾—æ™‚é–“æ¸¬å®š
            segments_fetch_start = time.time()
            segments_list = list(segments)
            segments_fetch_end = time.time()
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†æ™‚é–“æ¸¬å®š
            segments_process_start = time.time()
            segment_texts = []
            
            for segment in segments_list:
                print(f"ğŸ“ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: '{segment.text}' (ä¿¡é ¼åº¦: {segment.avg_logprob:.2f})")
                segment_texts.append(segment.text)
            
            segments_process_end = time.time()
            
            # æ–‡å­—åˆ—çµåˆæ™‚é–“æ¸¬å®š
            join_start = time.time()
            transcribed_text = "".join(segment_texts)
            join_end = time.time()
            
            # æ¸¬å®šãƒã‚¤ãƒ³ãƒˆ5: ãƒ†ã‚­ã‚¹ãƒˆçµåˆå®Œäº†
            text_combine_end = time.time()
            
            if transcribed_text.strip():
                print(f"ğŸ“ å¤‰æ›çµæœ: '{transcribed_text}'")
                
                # ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥æ™‚é–“æ¸¬å®šé–‹å§‹
                insert_start = time.time()
                
                # ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥ï¼ˆã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰çµŒç”±â†’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                success = self.insert_text_via_clipboard(transcribed_text)
                
                if not success:
                    print("ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç›´æ¥å…¥åŠ›ã‚’è©¦è¡Œ")
                    try:
                        pyautogui.write(transcribed_text)
                        print("âœ… ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥å®Œäº†ï¼ˆç›´æ¥å…¥åŠ›ï¼‰")
                        success = True
                    except Exception as e:
                        print(f"âŒ ç›´æ¥å…¥åŠ›ã‚‚å¤±æ•—: {e}")
                        # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¨ãƒ©ãƒ¼
                        self.play_sound_async('error')
                        return
                
                insert_end = time.time()
                
                # Phase 7-C: è©³ç´°å‡¦ç†æ™‚é–“ãƒ­ã‚°å‡ºåŠ›
                audio_prep_time = wav_save_start - audio_prep_start
                wav_save_time = wav_save_end - wav_save_start
                whisper_prep_time = whisper_start - wav_save_end
                whisper_time = whisper_end - whisper_start
                text_combine_time = text_combine_end - text_combine_start
                insert_time = insert_end - insert_start
                total_time = insert_end - process_start
                
                print("="*60)
                print("ğŸ”¬ Phase 7-C è©³ç´°æ™‚é–“åˆ†æ:")
                print(f"ğŸ“Š éŒ²éŸ³æ™‚é–“: {duration:.2f}ç§’")
                print(f"ğŸ”§ éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†: {audio_prep_time:.2f}ç§’")
                print(f"ğŸ’¾ WAVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {wav_save_time:.2f}ç§’") 
                print(f"âš™ï¸ Whisperå‰æº–å‚™: {whisper_prep_time:.2f}ç§’")
                print(f"ğŸ¤ Whisperå‡¦ç†: {whisper_time:.2f}ç§’")
                print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆçµåˆ: {text_combine_time:.2f}ç§’")
                print(f"  â”” ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå–å¾—: {segments_fetch_end - segments_fetch_start:.2f}ç§’")
                print(f"  â”” ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†: {segments_process_end - segments_process_start:.2f}ç§’")
                print(f"  â”” æ–‡å­—åˆ—çµåˆ: {join_end - join_start:.2f}ç§’")
                print(f"ğŸ“‹ ãƒ†ã‚­ã‚¹ãƒˆæŒ¿å…¥: {insert_time:.2f}ç§’")
                print(f"â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
                print("="*60)
                
            else:
                print("âŒ éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¨ãƒ©ãƒ¼
                self.play_sound_async('error')
                
        except Exception as e:
            print(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            # ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ã‚¨ãƒ©ãƒ¼
            self.play_sound_async('error')
        
        print("-" * 50)

    def on_press(self, key):
        """ã‚­ãƒ¼æŠ¼ä¸‹æ™‚ã®å‡¦ç†"""
        try:
            if key == keyboard.Key.esc:
                self.start_recording()
        except AttributeError:
            pass

    def on_release(self, key):
        """ã‚­ãƒ¼é›¢ã—æ™‚ã®å‡¦ç†"""
        try:
            if key == keyboard.Key.esc:
                self.stop_recording()
        except AttributeError:
            pass

    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ"""
        print("ğŸš€ éŸ³å£°å…¥åŠ›ãƒ„ãƒ¼ãƒ« Phase S-1 é–‹å§‹")
        print("ğŸ’¡ Escã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ã„ã‚‹é–“éŒ²éŸ³ã•ã‚Œã¾ã™")
        print("ğŸµ éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: ãƒ”ãƒƒ(é–‹å§‹) â†’ ãƒ”ãƒ”ãƒƒ(å®Œäº†)")
        
        # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒªã‚¹ãƒŠãƒ¼é–‹å§‹
        with keyboard.Listener(
            on_press=self.on_press,
            on_release=self.on_release
        ) as listener:
            try:
                listener.join()
                    
            except KeyboardInterrupt:
                print("\nğŸ›‘ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
            finally:
                if self.stream:
                    self.stream.stop()
                    self.stream.close()

if __name__ == "__main__":
    tool = VoiceInputTool()
    tool.run()